"""
===============================================================================
                    ALGORITMO K-NEAREST NEIGHBORS (KNN)
                    CLASSIFICAÃ‡ÃƒO DO DATASET IRIS
===============================================================================

DESCRIÃ‡ÃƒO DA TAREFA:
-------------------
Este script implementa o algoritmo KNN para classificar flores do dataset Iris.
O dataset contÃ©m 150 instÃ¢ncias de 3 tipos de flores (50 de cada tipo):
- Iris-setosa
- Iris-versicolor 
- Iris-virginica

Cada flor Ã© descrita por 4 atributos (em centÃ­metros):
- sepal_length (comprimento da sÃ©pala)
- sepal_width (largura da sÃ©pala)
- petal_length (comprimento da pÃ©tala)
- petal_width (largura da pÃ©tala)

OBJETIVO:
---------
Treinar um modelo KNN que consiga prever o tipo de uma flor baseado
nas medidas de suas sÃ©palas e pÃ©talas.

MÃ‰TRICA DE AVALIAÃ‡ÃƒO:
--------------------
AcurÃ¡cia: porcentagem de previsÃµes corretas em relaÃ§Ã£o ao total de previsÃµes.

"""

import pandas as pd
import numpy as np
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ============================================================================
# ETAPA 1: CARREGAR E PREPARAR OS DADOS
# ============================================================================

# 1ï¸âƒ£ Carregar o dataset do arquivo
# O arquivo contÃ©m 150 linhas, cada uma com 4 medidas + 1 classe
print("ğŸ“‚ Carregando dataset...")
df = pd.read_csv("dataset-iris.txt", header=None)
df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']
print(f"   âœ… {len(df)} instÃ¢ncias carregadas")

# 2ï¸âƒ£ Separar atributos (X) e classes (y)
# X = matriz com as 4 medidas de cada flor (features)
# y = vetor com o tipo de cada flor (target/classes)
print("\nğŸ”¢ Separando atributos e classes...")
X = df.iloc[:, :-1].values  # Primeiras 4 colunas (atributos)
y = df.iloc[:, -1].values   # Ãšltima coluna (classes)
print(f"   âœ… X: {X.shape} (instÃ¢ncias x atributos)")
print(f"   âœ… y: {len(y)} classes")

# 3ï¸âƒ£ Dividir em conjuntos de treino (70%) e teste (30%)
# Treino: dados que o algoritmo usa para "aprender"
# Teste: dados que usamos para avaliar se o algoritmo aprendeu bem
print("\nâœ‚ï¸  Dividindo dados em treino e teste...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
print(f"   âœ… Treino: {len(X_train)} instÃ¢ncias (70%)")
print(f"   âœ… Teste: {len(X_test)} instÃ¢ncias (30%)")

# 4ï¸âƒ£ Normalizar os dados (colocar todas as medidas na mesma escala)
# Importante porque as medidas tÃªm escalas diferentes (ex: 1.0 vs 5.0)
# Sem normalizaÃ§Ã£o, medidas maiores dominam o cÃ¡lculo da distÃ¢ncia
print("\nğŸ“ Normalizando os dados...")
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)  # Aprende a escala com dados de treino
X_test = scaler.transform(X_test)        # Aplica a mesma escala nos dados de teste
print("   âœ… Dados normalizados (mÃ©dia=0, desvio=1)")

# ============================================================================
# ETAPA 2: IMPLEMENTAR O ALGORITMO KNN
# ============================================================================

def euclidean_distance(a, b):
    """
    Calcula a distÃ¢ncia euclidiana entre dois pontos.
    
    Ã‰ como medir a distÃ¢ncia "em linha reta" entre duas flores
    baseado em suas caracterÃ­sticas (sÃ©palas e pÃ©talas).
    
    Quanto MENOR a distÃ¢ncia, mais PARECIDAS sÃ£o as flores!
    """
    return np.sqrt(np.sum((a - b) ** 2))

def knn_predict(X_train, y_train, X_test_instance, k):
    """
    Classifica UMA flor usando o algoritmo KNN.
    
    PASSO A PASSO:
    1. Calcula distÃ¢ncia da flor para TODAS as flores de treino
    2. Encontra as K flores mais parecidas (menores distÃ¢ncias)  
    3. VÃª qual tipo de flor Ã© mais comum entre essas K vizinhas
    4. Essa Ã© a previsÃ£o! (votaÃ§Ã£o majoritÃ¡ria)
    """
    # Calcula distÃ¢ncia para todas as flores de treino
    distances = [euclidean_distance(X_test_instance, x_train) for x_train in X_train]
    
    # Encontra os Ã­ndices das K menores distÃ¢ncias
    k_indices = np.argsort(distances)[:k]
    
    # Pega as classes das K flores mais prÃ³ximas  
    k_nearest_labels = [y_train[i] for i in k_indices]
    
    # VotaÃ§Ã£o: qual classe aparece mais vezes?
    most_common = Counter(k_nearest_labels).most_common(1)
    return most_common[0][0]

def knn(X_train, y_train, X_test, k):
    """
    Classifica MÃšLTIPLAS flores de uma vez.
    
    Aplica o KNN para cada flor do conjunto de teste.
    """
    return [knn_predict(X_train, y_train, x_test, k) for x_test in X_test]

# ============================================================================
# ETAPA 3: TREINAR E AVALIAR O MODELO
# ============================================================================

# 6ï¸âƒ£ Configurar e executar o KNN
# k=5 significa que vamos olhar os 5 vizinhos mais prÃ³ximos para decidir
print("\nğŸ¤– Executando o algoritmo KNN...")
k = 5
print(f"   ğŸ”¢ Usando k = {k} vizinhos")

# Fazer previsÃµes para todas as flores do conjunto de teste
y_pred = knn(X_train, y_train, X_test, k)
print(f"   âœ… {len(y_pred)} previsÃµes realizadas")

# 7ï¸âƒ£ Calcular a acurÃ¡cia (mÃ©trica de avaliaÃ§Ã£o)
def accuracy(y_true, y_pred):
    """
    Calcula a acurÃ¡cia: quantas previsÃµes estavam corretas?
    
    FÃ³rmula: acertos / total_de_previsÃµes
    Resultado: valor entre 0.0 (0%) e 1.0 (100%)
    """
    return np.sum(np.array(y_true) == np.array(y_pred)) / len(y_true)

print("\nğŸ“Š Avaliando o desempenho do modelo...")
acc = accuracy(y_test, y_pred)

# ============================================================================
# ETAPA 4: EXIBIR OS RESULTADOS COMPLETOS
# ============================================================================

# Calcular estatÃ­sticas detalhadas
total_previsoes = len(y_test)
total_acertos = int(acc * total_previsoes)
total_erros = total_previsoes - total_acertos

print("\n" + "="*60)
print("ğŸ¯ RESULTADOS FINAIS DA CLASSIFICAÃ‡ÃƒO KNN")
print("="*60)

# InformaÃ§Ãµes do modelo
print(f"\nğŸ”§ CONFIGURAÃ‡ÃƒO DO MODELO:")
print(f"   Algoritmo: K-Nearest Neighbors (KNN)")
print(f"   NÃºmero de vizinhos (k): {k}")
print(f"   Total de instÃ¢ncias de teste: {total_previsoes}")

# MÃ©tricas de desempenho
print(f"\nğŸ“Š DESEMPENHO DO MODELO:")
print(f"   âœ… Acertos: {total_acertos}")
print(f"   âŒ Erros: {total_erros}")
print(f"   ğŸ¯ AcurÃ¡cia: {acc:.4f} ({acc*100:.2f}%)")

# InterpretaÃ§Ã£o da acurÃ¡cia
if acc >= 0.95:
    interpretacao = "EXCELENTE! ğŸŒŸğŸŒŸğŸŒŸ"
elif acc >= 0.90:
    interpretacao = "MUITO BOM! âœ…âœ…"
elif acc >= 0.80:
    interpretacao = "BOM! ğŸ‘"
else:
    interpretacao = "PRECISA MELHORAR âš ï¸"

print(f"   ğŸ“ˆ AvaliaÃ§Ã£o: {interpretacao}")

print("-"*60)

# Exemplos de previsÃµes (melhorados)
print(f"\nğŸ“ EXEMPLOS DE PREVISÃ•ES (primeiros 15 casos):")
print(f"{'#':<3} | {'Real':<15} | {'Previsto':<15} | {'Status':<10}")
print("-"*55)

for i, (real, pred) in enumerate(zip(y_test[:15], y_pred[:15]), 1):
    status = "âœ… Acerto" if real == pred else "âŒ Erro" 
    print(f"{i:2d}  | {real:<15} | {pred:<15} | {status}")

# Resumo por classe (anÃ¡lise detalhada)
print(f"\nğŸ“Š ANÃLISE POR CLASSE:")
print(f"{'Classe':<15} | {'Total':<6} | {'Acertos':<8} | {'AcurÃ¡cia':<10}")
print("-"*50)

classes_unicas = np.unique(y_test)
for classe in classes_unicas:
    # MÃ¡scara para filtrar apenas instÃ¢ncias desta classe
    mask = y_test == classe
    y_real_classe = y_test[mask]
    y_pred_classe = np.array(y_pred)[mask]
    
    total_classe = len(y_real_classe)
    acertos_classe = np.sum(y_real_classe == y_pred_classe)
    acuracia_classe = acertos_classe / total_classe
    
    print(f"{classe:<15} | {total_classe:>5} | {acertos_classe:>7} | {acuracia_classe*100:>7.2f}%")

print("\n" + "="*60)
print("âœ… ANÃLISE COMPLETA! O modelo KNN foi avaliado com sucesso.")
print("="*60)
