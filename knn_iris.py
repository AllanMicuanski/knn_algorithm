"""
===============================================================================
                    ALGORITMO K-NEAREST NEIGHBORS (KNN)
                    CLASSIFICA√á√ÉO DO DATASET IRIS
===============================================================================

DESCRI√á√ÉO DA TAREFA:
-------------------
Este script implementa o algoritmo KNN para classificar flores do dataset Iris.
O dataset cont√©m 150 inst√¢ncias de 3 tipos de flores (50 de cada tipo):
- Iris-setosa
- Iris-versicolor 
- Iris-virginica

Cada flor √© descrita por 4 atributos (em cent√≠metros):
- sepal_length (comprimento da s√©pala)
- sepal_width (largura da s√©pala)
- petal_length (comprimento da p√©tala)
- petal_width (largura da p√©tala)

OBJETIVO:
---------
Treinar um modelo KNN que consiga prever o tipo de uma flor baseado
nas medidas de suas s√©palas e p√©talas.

M√âTRICA DE AVALIA√á√ÉO:
--------------------
Acur√°cia: porcentagem de previs√µes corretas em rela√ß√£o ao total de previs√µes.

"""

import pandas as pd
import numpy as np
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ============================================================================
# ETAPA 1: CARREGAR E PREPARAR OS DADOS
# ============================================================================

# 1Ô∏è‚É£ Carregar o dataset do arquivo
# O arquivo cont√©m 150 linhas, cada uma com 4 medidas + 1 classe
print("üìÇ Carregando dataset...")
df = pd.read_csv("dataset-iris.txt", header=None)
df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']
print(f"   ‚úÖ {len(df)} inst√¢ncias carregadas")

# 2Ô∏è‚É£ Separar atributos (X) e classes (y)
# X = matriz com as 4 medidas de cada flor (features)
# y = vetor com o tipo de cada flor (target/classes)
print("\nüî¢ Separando atributos e classes...")
X = df.iloc[:, :-1].values  # Primeiras 4 colunas (atributos)
y = df.iloc[:, -1].values   # √öltima coluna (classes)
print(f"   ‚úÖ X: {X.shape} (inst√¢ncias x atributos)")
print(f"   ‚úÖ y: {len(y)} classes")

# 3Ô∏è‚É£ Dividir em conjuntos de treino (70%) e teste (30%)
# Treino: dados que o algoritmo usa para "aprender"
# Teste: dados que usamos para avaliar se o algoritmo aprendeu bem
print("\n‚úÇÔ∏è  Dividindo dados em treino e teste...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
print(f"   ‚úÖ Treino: {len(X_train)} inst√¢ncias (70%)")
print(f"   ‚úÖ Teste: {len(X_test)} inst√¢ncias (30%)")

# 4Ô∏è‚É£ Normalizar os dados (colocar todas as medidas na mesma escala)
# Importante porque as medidas t√™m escalas diferentes (ex: 1.0 vs 5.0)
# Sem normaliza√ß√£o, medidas maiores dominam o c√°lculo da dist√¢ncia
print("\nüìè Normalizando os dados...")
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)  # Aprende a escala com dados de treino
X_test = scaler.transform(X_test)        # Aplica a mesma escala nos dados de teste
print("   ‚úÖ Dados normalizados (m√©dia=0, desvio=1)")

# ============================================================================
# ETAPA 2: IMPLEMENTAR O ALGORITMO KNN
# ============================================================================

def euclidean_distance(a, b):
    """
    Calcula a dist√¢ncia euclidiana entre dois pontos.
    
    √â como medir a dist√¢ncia "em linha reta" entre duas flores
    baseado em suas caracter√≠sticas (s√©palas e p√©talas).
    
    Quanto MENOR a dist√¢ncia, mais PARECIDAS s√£o as flores!
    """
    return np.sqrt(np.sum((a - b) ** 2))

def knn_predict(X_train, y_train, X_test_instance, k):
    """
    Classifica UMA flor usando o algoritmo KNN.
    
    PASSO A PASSO:
    1. Calcula dist√¢ncia da flor para TODAS as flores de treino
    2. Encontra as K flores mais parecidas (menores dist√¢ncias)  
    3. V√™ qual tipo de flor √© mais comum entre essas K vizinhas
    4. Essa √© a previs√£o! (vota√ß√£o majorit√°ria)
    """
    # Calcula dist√¢ncia para todas as flores de treino
    distances = [euclidean_distance(X_test_instance, x_train) for x_train in X_train]
    
    # Encontra os √≠ndices das K menores dist√¢ncias
    k_indices = np.argsort(distances)[:k]
    
    # Pega as classes das K flores mais pr√≥ximas  
    k_nearest_labels = [y_train[i] for i in k_indices]
    
    # Vota√ß√£o: qual classe aparece mais vezes?
    most_common = Counter(k_nearest_labels).most_common(1)
    return most_common[0][0]

def knn(X_train, y_train, X_test, k):
    """
    Classifica M√öLTIPLAS flores de uma vez.
    
    Aplica o KNN para cada flor do conjunto de teste.
    """
    return [knn_predict(X_train, y_train, x_test, k) for x_test in X_test]

# ============================================================================
# ETAPA 3: TREINAR E AVALIAR O MODELO
# ============================================================================

# 6Ô∏è‚É£ Configurar e executar o KNN
# k=5 significa que vamos olhar os 5 vizinhos mais pr√≥ximos para decidir
print("\nü§ñ Executando o algoritmo KNN...")
k = 5
print(f"   üî¢ Usando k = {k} vizinhos")

# Fazer previs√µes para todas as flores do conjunto de teste
y_pred = knn(X_train, y_train, X_test, k)
print(f"   ‚úÖ {len(y_pred)} previs√µes realizadas")

# 7Ô∏è‚É£ Calcular a acur√°cia (m√©trica de avalia√ß√£o)
def accuracy(y_true, y_pred):
    """
    Calcula a acur√°cia: quantas previs√µes estavam corretas?
    
    F√≥rmula: acertos / total_de_previs√µes
    Resultado: valor entre 0.0 (0%) e 1.0 (100%)
    """
    return np.sum(np.array(y_true) == np.array(y_pred)) / len(y_true)

print("\nüìä Avaliando o desempenho do modelo...")
acc = accuracy(y_test, y_pred)

# ============================================================================
# ETAPA 4: EXIBIR OS RESULTADOS
# ============================================================================

print("\n" + "="*50)
print("üéØ RESULTADOS DA CLASSIFICA√á√ÉO KNN")
print("="*50)
print(f"N√∫mero de vizinhos (k): {k}")
print(f"Acur√°cia do modelo: {acc:.2f} ({acc*100:.2f}%)")
print("-"*50)

print(f"\nüìù Exemplos de previs√µes:")
print(f"{'Real':<15} | {'Previsto':<15} | Status")
print("-"*45)
for real, pred in zip(y_test[:10], y_pred[:10]):
    status = "‚úÖ Correto" if real == pred else "‚ùå Erro" 
    print(f"{real:<15} | {pred:<15} | {status}")
