# ğŸŒ¸ ClassificaÃ§Ã£o Iris - KNN e SVM com ValidaÃ§Ã£o Cruzada

> Projeto acadÃªmico de Machine Learning implementando algoritmos KNN e SVM para classificaÃ§Ã£o do dataset Iris usando validaÃ§Ã£o cruzada.

[![Python](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## ğŸ“‹ SumÃ¡rio

- [Sobre o Projeto](#-sobre-o-projeto)
- [Resultados](#-resultados)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Como Usar](#-como-usar)
- [Algoritmos Implementados](#-algoritmos-implementados)
- [Conceitos Importantes](#-conceitos-importantes)
- [Dataset](#-dataset)
- [Autor](#-autor)

## ğŸ¯ Sobre o Projeto

Este projeto implementa e compara dois algoritmos clÃ¡ssicos de Machine Learning para classificaÃ§Ã£o de flores Iris:

- **KNN (K-Nearest Neighbors)** - ImplementaÃ§Ã£o customizada
- **SVM (Support Vector Machine)** - Usando scikit-learn

### CaracterÃ­sticas Principais

âœ… ImplementaÃ§Ã£o modular e profissional  
âœ… ValidaÃ§Ã£o cruzada estratificada (5-fold)  
âœ… AnÃ¡lise completa com matriz de confusÃ£o  
âœ… MÃ©tricas detalhadas: AcurÃ¡cia, PrecisÃ£o, RevocaÃ§Ã£o, F1-Score  
âœ… ComparaÃ§Ã£o entre modelos  
âœ… CÃ³digo bem documentado e testado

## ğŸ† Resultados

### Desempenho dos Modelos

| Modelo  | AcurÃ¡cia           | PrecisÃ£o   | RevocaÃ§Ã£o  | F1-Score   |
| ------- | ------------------ | ---------- | ---------- | ---------- |
| **KNN** | 94.00% Â± 6.46%     | 94.29%     | 94.00%     | 94.01%     |
| **SVM** | **95.33% Â± 4.52%** | **95.49%** | **95.33%** | **95.32%** |

### Matriz de ConfusÃ£o - SVM (Melhor Modelo)

```
                    Predito
Verdadeiro   Setosa  Versicolor  Virginica
Setosa         50        0          0
Versicolor      0       48          2
Virginica       0        2         48
```

**ğŸ¥‡ Vencedor:** SVM com 95.33% de acurÃ¡cia

## ğŸ“ Estrutura do Projeto

```
KNN/
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ requirements.txt             # DependÃªncias do projeto
â”œâ”€â”€ main_np2.py                  # Script principal (NP2)
â”œâ”€â”€ knn_iris.py                  # ImplementaÃ§Ã£o original simplificada
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset-iris.txt         # Dataset Iris
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ data_loader.py       # Carregamento e preprocessamento
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ knn.py               # Algoritmo KNN customizado
    â”‚   â””â”€â”€ svm.py               # Wrapper SVM
    â”œâ”€â”€ evaluation/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ metrics.py           # MÃ©tricas e validaÃ§Ã£o cruzada
    â”‚   â””â”€â”€ confusion_matrix.py  # AnÃ¡lise de matriz de confusÃ£o
    â””â”€â”€ visualization/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ plots.py             # GrÃ¡ficos (opcional)
```

## ğŸš€ Como Usar

### 1. PrÃ©-requisitos

- Python 3.13+ (recomendado)
- pip (gerenciador de pacotes Python)

### 2. InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/AllanMicuanski/knn_algorithm.git
cd knn_algorithm

# Crie um ambiente virtual (recomendado)
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

# Instale as dependÃªncias
pip install -r requirements.txt
```

### 3. Executar o Projeto

#### OpÃ§Ã£o 1: Atividade NP2 Completa (Recomendado)

```bash
python main_np2.py
```

**SaÃ­da esperada:**

- âœ… Carregamento e preprocessamento dos dados
- ğŸ¤– ConfiguraÃ§Ã£o dos modelos KNN e SVM
- ğŸ”¬ ValidaÃ§Ã£o cruzada (5-fold) para ambos
- ğŸ“Š Matrizes de confusÃ£o detalhadas
- âš–ï¸ ComparaÃ§Ã£o entre modelos
- ï¿½ AnÃ¡lise final com insights

#### OpÃ§Ã£o 2: Teste RÃ¡pido

```bash
python main_np2.py --test
```

Executa apenas um teste bÃ¡sico para verificar se tudo estÃ¡ funcionando.

#### OpÃ§Ã£o 3: ImplementaÃ§Ã£o Original Simples

```bash
python knn_iris.py
```

VersÃ£o simplificada com apenas KNN.

### 4. Usando o Ambiente Virtual

**Por que usar ambiente virtual?**

O ambiente virtual (`.venv`) Ã© como um "apartamento separado" para as bibliotecas do projeto:

- âœ… NÃ£o interfere com outras instalaÃ§Ãµes Python
- âœ… MantÃ©m versÃµes especÃ­ficas das bibliotecas
- âœ… Facilita compartilhamento do projeto

**Comandos importantes:**

```bash
# Ativar ambiente virtual
source .venv/bin/activate        # Linux/Mac
.venv\Scripts\activate           # Windows

# Desativar quando terminar
deactivate

# Usar Python do ambiente virtual
.venv/bin/python main_np2.py     # Linux/Mac
.venv\Scripts\python main_np2.py # Windows
```

## ğŸ¤– Algoritmos Implementados

### KNN (K-Nearest Neighbors)

**Como funciona:**

1. Calcula a distÃ¢ncia euclidiana entre a nova amostra e todas as amostras conhecidas
2. Seleciona os K vizinhos mais prÃ³ximos (K=3 neste projeto)
3. Classifica baseado na votaÃ§Ã£o majoritÃ¡ria dos vizinhos

**CaracterÃ­sticas:**

- âœ… ImplementaÃ§Ã£o customizada em Python puro
- âœ… Usa distÃ¢ncia euclidiana
- âœ… Interface compatÃ­vel com scikit-learn
- âœ… K=3 (testado empiricamente)

**CÃ³digo simplificado:**

```python
def _euclidean_distance(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))

def predict(X):
    distances = [_euclidean_distance(x, x_train) for x_train in X_train]
    k_nearest = np.argsort(distances)[:k]
    k_labels = y_train[k_nearest]
    return most_common_label(k_labels)
```

### SVM (Support Vector Machine)

**Como funciona:**

1. Encontra o hiperplano que melhor separa as classes
2. Maximiza a margem entre as classes
3. Usa kernel RBF para problemas nÃ£o-lineares

**CaracterÃ­sticas:**

- âœ… Usa scikit-learn (`SVC`)
- âœ… Kernel RBF (Radial Basis Function)
- âœ… C=1.0 (parÃ¢metro de regularizaÃ§Ã£o)
- âœ… Excelente para problemas nÃ£o-lineares

## ğŸ’¡ Conceitos Importantes

### ValidaÃ§Ã£o Cruzada (Cross-Validation)

**O que Ã©?**

TÃ©cnica para avaliar modelos de forma mais robusta, dividindo os dados em K partes (folds):

```
Fold 1: [TESTE] [TREINO] [TREINO] [TREINO] [TREINO]
Fold 2: [TREINO] [TESTE] [TREINO] [TREINO] [TREINO]
Fold 3: [TREINO] [TREINO] [TESTE] [TREINO] [TREINO]
Fold 4: [TREINO] [TREINO] [TREINO] [TESTE] [TREINO]
Fold 5: [TREINO] [TREINO] [TREINO] [TREINO] [TESTE]
```

**Por que usar?**

- âœ… Usa todos os dados para treino e teste
- âœ… Reduz viÃ©s da divisÃ£o aleatÃ³ria
- âœ… Fornece mÃ©dia e desvio padrÃ£o da performance
- âœ… Mais confiÃ¡vel que train/test simples

### Matriz de ConfusÃ£o

Mostra onde o modelo acerta e erra:

```
                Predito
Verdadeiro   A    B    C
    A       50    0    0  â† Todos os A foram classificados corretamente
    B        0   48    2  â† 2 B foram classificados como C
    C        0    2   48  â† 2 C foram classificados como B
```

### MÃ©tricas de AvaliaÃ§Ã£o

| MÃ©trica       | FÃ³rmula                 | O que mede                                                  |
| ------------- | ----------------------- | ----------------------------------------------------------- |
| **AcurÃ¡cia**  | `Acertos / Total`       | Porcentagem geral de acertos                                |
| **PrecisÃ£o**  | `VP / (VP + FP)`        | De todos que classifiquei como X, quantos eram realmente X? |
| **RevocaÃ§Ã£o** | `VP / (VP + FN)`        | De todos os X verdadeiros, quantos eu encontrei?            |
| **F1-Score**  | `2 Ã— (P Ã— R) / (P + R)` | MÃ©dia harmÃ´nica de PrecisÃ£o e RevocaÃ§Ã£o                     |

**Legenda:** VP = Verdadeiros Positivos, FP = Falsos Positivos, FN = Falsos Negativos

### NormalizaÃ§Ã£o de Dados

**Por que normalizar?**

As features tÃªm escalas diferentes:

- Comprimento da sÃ©pala: 4.3 - 7.9 cm
- Largura da pÃ©tala: 0.1 - 2.5 cm

Sem normalizaÃ§Ã£o, features com valores maiores "dominam" o cÃ¡lculo de distÃ¢ncia.

**StandardScaler:**

```python
X_normalizado = (X - mÃ©dia) / desvio_padrÃ£o
```

Resultado: Todas as features com mÃ©dia=0 e desvio=1

## ğŸ“Š Dataset

### Dataset Iris

Criado por Ronald Fisher em 1936, Ã© um dos datasets mais famosos em Machine Learning.

**CaracterÃ­sticas:**

- ğŸ“¦ **150 instÃ¢ncias** (50 de cada classe)
- ğŸ·ï¸ **3 classes:** Iris-setosa, Iris-versicolor, Iris-virginica
- ğŸ“ **4 features numÃ©ricas:**
  - Comprimento da sÃ©pala (cm)
  - Largura da sÃ©pala (cm)
  - Comprimento da pÃ©tala (cm)
  - Largura da pÃ©tala (cm)

**DistribuiÃ§Ã£o equilibrada:**

- Iris-setosa: 50 amostras (33.33%)
- Iris-versicolor: 50 amostras (33.33%)
- Iris-virginica: 50 amostras (33.33%)

**Dificuldade:** Moderada

- Iris-setosa Ã© linearmente separÃ¡vel
- Iris-versicolor e Iris-virginica tÃªm alguma sobreposiÃ§Ã£o

## ï¿½ ReferÃªncias

- [Iris Dataset - UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/iris)
- [scikit-learn Documentation](https://scikit-learn.org/stable/)
- [K-Nearest Neighbors Algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)
- [Support Vector Machine](https://en.wikipedia.org/wiki/Support_vector_machine)

## ğŸ‘¤ Autor

**Allan Micuanski**

- GitHub: [@AllanMicuanski](https://github.com/AllanMicuanski)
- Projeto: Atividade NP2 - InteligÃªncia Artificial

## ğŸ“ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto e estÃ¡ disponÃ­vel para fins educacionais.
